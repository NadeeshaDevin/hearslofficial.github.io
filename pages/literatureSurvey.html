<!DOCTYPE html>
<html>
<head>
    <title>Static Web Page</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f0f0f0;
            margin: 0;
            padding: 0;
        }

        .container {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            padding: 20px;
        }

        .left-column {
            width: 48%;
            padding: 10px;
            background-color: #fff;
        }

        .right-column {
            width: 48%;
            padding: 10px;
            background-color: #fff;
        }
    </style>
</head>
<body>
     <div  style="text-align: center;">
          <h1>Literature Survey</h1>
      </div>
    <div class="container">
        <div class="left-column" text-align = "center">
            <h1>Overview</h1>
            <p>
                In the past, individuals with hearing and speech impairments in Sri Lanka encountered significant challenges while trying to integrate into society. Due to their disabilities, they faced difficulties in communicating effectively with others. Their primary means of expressing their needs, emotions, and feelings to the world was through Sign Language. However, a significant barrier existed as most of society was unfamiliar with Sign Language. Consequently, those with disabilities had to rely on individuals proficient in Sign Language to facilitate communication with those who did not understand it. Without this intermediary, it was often challenging for ordinary individuals to comprehend what the disabled person was trying to convey.
                <br /><br />
                Moreover, while numerous applications and devices worldwide were available for translating Sign Language into English and other languages, there was a noticeable gap in the Sri Lankan context. Although there had been research efforts to create applications that could translate Sign Language into Sinhala, these applications had limitations. For instance, some could only convert one sign at a time into a single word or letter in Sinhala. There were no applications capable of translating entire sign language presentations into Sinhala through methods like video recording. Our project aimed to address this gap by developing an application with the ability to perform such translations.
                <br /><br />
                Another observation was that ordinary people had various means of communication through applications designed for speaking, listening, and visual interaction. However, individuals with hearing impairments, speech impairments, and visual impairments faced challenges in using these applications. To bridge this gap, we endeavored to create a specialized chat application that facilitated seamless communication between those with hearing and speech impairments and the general population. This chat application was complemented by our Sign Language to Sinhala language converter, making it an inclusive tool for all.
            </p>
        </div>
        <div class="right-column">
            <h1>Previous Surveys</h1>
            <p>
                <strong>Prototype Machine Translation System From Text-To-Indian Sign Language (2008):</strong> In 2008, Tirthankar Dasgupta, Sandipan Dandpat, and Anupam Basu introduced a prototype machine translation system aimed at serving as a teaching and learning tool for Indian Sign Language. The system accepts simple English sentences as input and facilitates information retrieval. However, it lacks a sign synthesis module using animated avatars and detailed working descriptions.
                <br /><br />
                <strong>Sign Language to Speech Translation System Using PIC Microcontroller (2013):</strong> Gunasekaran K. and Manikandan R. developed a Sign Language to Speech Translation System in 2013, offering high dependability, rapid responsiveness, and precise hand movement. It is versatile, allowing the installation of different languages without altering the original code, but its main drawback is the increased manufacturing cost.
                <br /><br />
                <strong>Voice-Controlled Artificial Handspeak System (2014):</strong> In 2014, Jonathan Gatti, Carlo Fonda, Livio Tenze, and Enrique Canessa created a paper robotic hand prototype. Utilizing a low-cost 3D printer and open-source technology, the system is controlled by a voice recognition engine and Arduino UNO connected to a Raspberry Pi. The current iteration has some room for improvement.
                <br /><br />
                <strong>Translating Indian Sign Language to Text and Voice Messages (2015):</strong> "Translating Indian Sign Language to Text and Voice Messages" (2015) presents a system with portability and user independence, capable of interpreting sign language into text messages. It employs an energy-efficient microcontroller and a user-friendly smartphone application but comes with a higher cost.
                <br /><br />
                <strong>Intelligent Arabic Sign Language to Arabic Text Translation (2018):</strong> In 2018, A. E. E. El Alfi and S. M. EL Atawy introduced an intelligent Arabic Sign Language to Arabic text translation technology, supporting a mobile conversation app. While it effectively resolved language issues, it couldn't interpret text from Arabic into Arabic sign language and faced challenges in matching grammatical conventions.
                <br /><br />
                <strong>Voice to Sign Language Translation System for Malaysian Deaf People (2009):</strong> The 2009 paper "V2S: Voice to Sign Language Translation System for Malaysian Deaf People" by Oi Mean Foong, Tang Jung Low, and Wai Wan La discusses a system for Malaysian sign language. Its main advantage is voice support (English language), but it requires initial speech pattern training using spectral parameters.
                <br /><br />
                <strong>Android Application to Aid Uneducated Deaf-Dumb People (2014):</strong> Dalia Nashat, Abeer Shoker, Fowzyah Al-Swat, and Reem Al-Ebailan introduced an Android application in 2014 aimed at helping uneducated deaf and dumb individuals. It offers communication support, quizzes, games, and a sign language keyboard. However, it has limitations such as one sign per letter, Android OS support only, no face-to-face interaction, and a focus on teaching rather than practical use.
                <br /><br />
                <strong>Design and Implementation of a Sign Language Recognition System for Sinhala Language:</strong> H.M.D. Piumal and H.M.N. Dilum Bandara's work focuses on a sign language recognition system for Sinhala language. It employs sensor data and machine learning techniques like decision trees, naive bayes, and k-nearest neighbor algorithms to identify Sinhala sign language motions. The authors conducted tests using a specially designed sensor system to gather data from 10 Sinhala sign language motions.
            </p>
        </div>
    </div>
</body>
</html>
