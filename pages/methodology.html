<!DOCTYPE html>
<html>
<head>
    <title>Project Description</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
        }
        .container {
            max-width: 100%;
            max-height: 100%;
            margin: 0 auto;
            display: flex;
        }
        
        h1 {
            font-size: 24px;
            color: #333;
        }
        h2 {
            font-size: 20px;
            color: #333;
            font-weight: bold;
        }
        p {
            font-size: 16px;
            line-height: 1.5;
            text-align: justify;
            margin-bottom: 20px;
        }
        img {
            max-width: 100%;
            height: auto;
        }
        body {
            margin: 0;
            padding: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            overflow: hidden;
        }
        #zoomed-image {
            cursor: pointer;
            transition: transform 0.3s;
        }
        #zoomed-image.zoomed {
            transform: scale(2);
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="problem">
            <h1>Project Description</h1>
            
            <h2>A. Sign Language to Sinhala voice</h2>
            <p>This project focuses on creating a communication system for deaf-blind people that includes translating sign language to Singlish and then Singlish to Sinhala. It involves various steps, including a literature review, compiling a database of Singlish representations and corresponding Sinhala words, creating a dataset for Sinhala voice speech samples, examining phonetic patterns in Singlish, developing algorithms to handle variances in Singlish, and creating an interface for tactile communication. The goal is to enable voice-based communication for deaf-blind individuals through the synthesis of Sinhala words.</p>
    
            <h2>B. Sinhala voice to sign animation</h2>
            <p>This project aims to develop a deep learning model that can recognize spoken Sinhala and convert it into accurate sign language animations. The process involves gathering a dataset of spoken Sinhala and associated sign language animations, utilizing natural language processing techniques to transform spoken Sinhala into text, employing computer vision techniques to generate sign language animations, and creating an integrated system for real-time translation. The project also emphasizes user-friendly interfaces and rigorous testing for accuracy and efficiency.</p>
       
        
            <h2>C. Chat application for the deaf-blind community</h2>
            <p>This project involves the development of a chat application in Sinhala that can be used by people with various disabilities, including those who can't hear, can't talk, can't see, and normal users. The application supports different methods of message sending and receiving based on the user's disability, including sign emojis, animations, Sinhala letters, voice messages, or a combination of these methods. The system converts messages into various forms (Sinhala voice, Sinhala text, Sign Emojis, and Animations) based on user preferences. It describes the creation of special datasets, APIs for identifying sign animations and emojis, and the development of the chat application as a web application. The aim is to provide accessible communication options for a diverse user base.</p>
            
            
        </div>
    </div>
</body>
</html>
